[
  
    {

      "title"    : "Linux vs. FreeBSD vs. Windows",
      "url"      : "/posts/linux-freebsd-windows",
      "content"  : "Introduction\n\nThis paper presents a comparison between Linux, FreeBSD, and Windows in three areas: concurrency, I/O, and memory management. In addition, in each area, I will discussing about the differences and similarities between them.\n\nConcurrency Comparison\n\nIn this section, I will be discussing about processes, threads, CPU scheduling, and other related information that I have found interesting for each operating system based on my research.\n\nLinux\n\nEach process provides the resources needed to execute a program. A process has a virtual address space, executable code, open handles to system objects, a security context, a unique process identifier, environment variables, a priority class, minimum and maximum working set sizes, and at least one thread of execution. Each process is started with a single thread, often called the primary thread, but can create additional threads from any of its threads [1].\n\nTo create a process in Linux, we will need to use \\textit{Fork() system call}, which creates a new process, called the child process, from the exiting process, called the parent process. The child process has its own process ID (PID). \\textit{Fork()} takes no argument and return process ID. \\textit{Fork()} returns negative value if the process isn't created, zero if the child process is created, and positive value and a child process ID if \\textit{Fork()} returns from parent process. In addition, system call \\textit{Fork()} duplicate the same address space of the parent process and allocate to the child process. However, the child process doesn't inherit timer and semaphore adjustment from the parent process [2].\n\nThe following code sample demonstrates how to create a process in Linux [3]:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n#include &lt;unistd.h&gt;\n#include &lt;sys/types.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;sys/wait.h&gt;\n#include &lt;stdlib.h&gt;\n\nint main( )\n{\n    pid_t child_pid;   \n    child_pid = fork ( );                                    // Create a new child process;\n    if (child_pid &gt;= 0)                         \n    {\n        if (child_pid == 0)             \n        {\n            printf (\"child process successfully created!!\\n\");\n            printf (\"child PID =  %d, parent PID = %d\\n\", getpid( ), getppid( ) );\n            exit(0);\n         }\n    }\n    else\n    {\n        perror(\"fork\");\n        exit(0);\n    }\n}\n\n\nThreads of execution, often shortened to threads, are the objects of activity within the process. Each thread includes a unique program counter, process stack, and set of processor registers. The kernel schedules individual threads, not processes. In traditional Unix systems, each process consists of one thread. In modern systems, however, multi-threaded programs consist of more than one thread are common [1].\n\nFreeBSD\n\nA process is a program in execution. Each process has an address space containing a mapping of its program’s object code and global variables, a set of kernel resources that it can name and on which it can operate using system calls, and at least one and possibly many threads that execute its code. Every process in the system is assigned a unique identifier termed the process identifier (PID). An PID is a common mechanism used by applications and by the kernel to reference processes and it is used by applications when the latter send a signal to a process and when receiving the exit status from a deceased process. There are two PIDs that are special important to to each process:  the PID of the process itself and the PID of the process’s parent process. A process structure contains information that must always remain resident in main memory, along with references to other structures that remain resident [4].\n\nEvery thread represents a virtual processor with a full context worth of register state and its own stack mapped into the address space. In addition, every thread running in the process has a corresponding kernel thread, with its own kernel stack that represents the user thread when it is executing in the kernel as a result of a system call, page fault, or signal delivery. The threads of a process operate in either user mode or kernel mode. In user mode, a thread executes application code with the machine in a non-privileged protection mode. Thread structure tracks information that needs to be resident only when the process is executing such as its kernel run-time stack. Both, process and thread, structures are allocated dynamically as part of process creation and are freed when the process is destroyed as it exits [4].\n\nThe FreeBSD timeshare scheduler uses a priority-based scheduling policy that is biased to favor interactive programs, such as text editors, over long-running batch-type jobs. Interactive programs tend to exhibit short bursts of computation followed by periods of inactivity or I/O. The scheduling policy initially assigns a high execution priority to each thread and allows that thread to execute for a fixed time slice [4].\n\nWindows\n\nA process is basically a program in execution. The execution of a process must progress in a sequential fashion. Each process is uniquely identified by a number called a \\textit{process ID} (PID). Similar to files, each process has one owner and group, and the owner and group permissions are used to determine which files and devices the process can open [5].\n\nIn addition, to create a process in Windows, we will need to use CreateProcess function. CreateProcess function runs independently of the creating process, and the following code sample demonstrates how to create a process [5]:\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n#include &lt;windows.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;tchar.h&gt;\n\nvoid _tmain( int argc, TCHAR *argv[] )\n{\n    STARTUPINFO si;\n    PROCESS_INFORMATION pi;\n    ZeroMemory( &amp;si, sizeof(si) );\n    si.cb = sizeof(si);\n    ZeroMemory( &amp;pi, sizeof(pi) );\n    if( argc != 2 )\n    {\n        printf(\"Usage: %s [cmdline]\\n\", argv[0]);\n        return;\n    }\n    // Start the child process. \n    if( !CreateProcess( NULL,   // No module name (use command line)\n        argv[1],        // Command line\n        NULL,           // Process handle not inheritable\n        NULL,           // Thread handle not inheritable\n        FALSE,          // Set handle inheritance to FALSE\n        0,              // No creation flags\n        NULL,           // Use parent's environment block\n        NULL,           // Use parent's starting directory \n        &amp;si,            // Pointer to STARTUPINFO structure\n        &amp;pi )           // Pointer to PROCESS_INFORMATION structure\n    ) \n    {\n        printf( \"CreateProcess failed (%d).\\n\", GetLastError() );\n        return;\n    }\n    // Wait until child process exits.\n    WaitForSingleObject( pi.hProcess, INFINITE );\n    // Close process and thread handles. \n    CloseHandle( pi.hProcess );\n    CloseHandle( pi.hThread );\n}\n\n\nWindows implements a priority-driven, preemptive scheduling system, at least one of the highest priority ready threads always runs, with the caution that certain high-priority threads ready to run might be limited by the processors on which they might be allowed or preferred to run on, a phenomenon called processor affinity [6].\n\nGeneral Discussion\n\nFrom my research, they all have similar processes features and behaviors, and Windows' threads are similar to FreeBSD in the current model and the interface definition for Windows' threads are similar to Linux. In addition, FreeBSD and Windows have a similar CPU scheduling as they both use priority-queues. [1][2][4][5][6].\n\nIO Comparison\n\nIn this section, I will be discussing about I/O (block and character), data structures, algorithms, cryptography, I/O scheduling, types of devices, and other related information that I have found interesting for each operating system based on my research.\n\nFreeBSD\n\nThe basic model of the UNIX I/O system is a sequence of bytes that can be accessed either randomly or sequentially, and there aren't any access methods and control blocks in typical UNIX user process. Different programs expect various levels of structure, but the kernel doesn't impose structure on I/O. In addition, UNIX processes use a descriptor to reference I/O streams. Descriptors are small unsigned integers obtained from the open and socket system calls. Read and write system calls can be applied to descriptors to transfer data, and close system call can be used to dead-locate any descriptor. There are three types of descriptors, files, pipes, and sockets. Files are linear array bytes, has at least one name, exists until all its names are deleted explicitly, and no process holds a descriptor for it. Pipes are a linear array of bytes, no name, used as an I/O stream, it is unidirectional, and created by a pipe system call. Sockets are transient objects, used for interprocess communication, exists only as long as some process holds a descriptor referring to it, and created by a socket system call. Furthermore, hardware devices can be categorized as either block (structure) or character (unstructured). For block devices, they are typified by disks and magnetic tapes, the kernel supports read-modify-write-type buffering actions on block-oriented structured devices to allow latter to be read and written in a totally random byte addressed fashion, and the filesystems are created on block devices. For character devices, they are communication lines, raster plotters, and unbuffered magnetic tapes and disks, and are support large block I/O transfers [7].\n\nFor previous editions of stream I/O system, the stream I/O system was based on the UNIX character I/O system, which allows a user process to open a way terminal port and then to insert appropriated kernel-processing modules and the modules that are being processed by the network protocols can be inserted in the appreciated kernel-processing modules. In addition, stacking a terminal-processing module on top of a network-processing module allowed flexible and efficient implementation of the network viral terminals within the kernel. In newer editions of stream I/O system ,such as 18th edition which was adopted in System V. However, the design of the networking facilities for 4.2BSD changed its approach based on the socket interface and flexible multi-player network architecture, which allows a single system to support multiple sets of networking protocols with stream, datagram, and other types of access. In addition, the user application and the kernel operate independently of each other for security. In 4.4BSD, the kernel doesn't store I/O control blocks or other operating-system-related data structures in the application address space. Each user-level application is provided with an independent address space in which it executes its applications/processes. Moreover, the kernel makes most of the state changes invisible to the processes involved [7].\n\nFreeBSD supports two different disk encryption methods, GBDE and GELI, and both of the methods support different cryptographic algorithms that counter different threats. For GBDE, it is high-security (protecting the user as protecting the data), cryptographic key provided by the user, and when the key is lost, the data can't be accessed. On the other hand, GELI protects the data but doesn't protect the user, it uses FreeBSD's cryptographic device driver, and takes advantage of its transparently [8].\n\nWindows\n\nThe design goals for the Windows I/O system are to provide an abstraction of devices, both hardware and software to application with a selected features of the operating system, such as uniform security, high-performance asynchronous, high-level language support, etc. Windows I/O system is responsible for the connection between user model functionality, storage, and drivers with WDM WMI Routines, PnP Manager, Power Manager, and I/O Manager. For I/O Manager, it is the core of the Windows I/O system because it defines the order of the framework within which I/O requests are delivered to device drivers. Most I/O requests are represented as I/O Request Packet (IRP), which travels from one I/O system component to another. The design of Windows I/O system allows an individual application thread to manage multiple I/O requests concurrently [9].\n\nMoreover, I have found 4 interesting algorithms built within the driver structure, Initialization Routine, Opening Devices, IRP, and Completing an I/O Request. For the Initialization Routine, the I/O manager executes a driver's Initialization Routine when it loads the driver into the operating system. Then, the Initialization Routine fills in the system data structures to register the rest of the driver's routines with the I/O manager and performs any global driver initialization that is necessary. For the Opening Devices, a file object is in a kernel model data structure that represents a handle to a device, and this process allows synchronization and easy manipulation of the object files. For IRP, the IRP is where the I/O system stores information it needs to process an I/O request, so when a thread calls an I/O API, the I/O manager constructs an IRP to represent the operation as it progresses through the I/O system. For Completing an I/O Request, it starts when a driver calls IoCompleteRequest to inform the I/O manager that has completed process teh request specified in the IRP [9].\n\nI have found a good example[10] of how to use IoCompleteRequest in a Windows machine to implement Completing an I/O Request.\n\n1\n2\n3\n4\n5\n6\n7\nNTSTATUS CompleteRequest(PIRP Irp, NTSTATUS status, ULONG_PTR Information)\n{\n    Irp-&gt;IoStatus.Status = status;\n    Irp-&gt;IoStatus.Information = Information;\n    IoCompleteRequest(Irp, IO_NO_INCREMENT);\n    return status;\n}\n\n\nGeneral Discussion\n\nA comparison between FreeBSD, Linux, and Windows 2000, that FreeBSD and Linux have higher security compared to Windows 2000 because they are both open source and Windows 2000 is closed, which means the main developers need to detect errors in the system by themselve. However, FreeBSD has higher security than Linux beucase FreeBSD requires third parties verification of the system compared to Linux, which can accepts updates from anyone with minor verification. In addition, Windows 2000 is supported by most of device manufactures because its layered architecture and generic use of objects [11][12].\n\nTo sum up, it seems that FreeBSD has a Linux-like I/O system strcture compared to Windows which treats every file as an object. In addition, FreeBSD has higher security than Linux and Windows because FreeBSD has different methods to protect data. However, Windows is supported by most of device manufactures because its layered architecture and generic use of objects [7][8][9][11][12].\n\nMemory Management Comparison\n\nIn this section, I will be discussing about memory management in FreeBSD and Windows based on my research.\n\nFreeBSD\n\nBerkeley Software Distribution (BSD) kernel handles process scheduling, memory management, symmetric multi-processing, device drivers, etc. In addition, for memory management in general, each process has its own private address and each address space is divided into 3 logical segments: text, data, and stack. For the text segment, it is read-only, has initialized and uninitialized data portions of a program, and, in most machines, a process can change the size of its text segment only when the segment's contents are overlaid with data from the files system or when debugging in action. For the stack, it has application's run-time stack and makes a system call in most machines. Lastly, initial contents of the segments of a child process are duplicated from the segments of a parent process. Moreover, for memory management inside the kernel, kernel often does allocation of memory that are needed for only the duration of a single system call, but in a user process, such as short-term memory, would be allocated on the run-time stack. Kernel's memory isn't feasible to allocate even moderate-sized blocks of memory on it because the kernel has a limited run-time stack [7].\n\nFor memory management, kernel can't easily deal with memory allocation errors and often can't scheme. Therefore, getting the memory in the kernel is more complicated than in user-space. Moreover, kernel treats phsical pages as the basic unit of memory management and kernel represents every phsical page on the system with a struct page structure, which is defined in &lt;linux/mm_types.h&gt; [1].\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nstruct page {\n    unsigned long flags;\n    atomic_t _count;\n    atomic_t _mapcount;\n    unsigned long private;\n    struct address_space *mapping;\n    pgoff_t index;\n    struct list_head lru;\n    void *virtual;\n};\n\n\nThe kernel can't treat all pages as the same because the hardware limitation. Therefore, some pages can't be used for certain because of their physical address in memory. Hence, kernel uses the zones to group pages of similar properties. Linux partitions the system's pages into zones to have a pooling in place to satisfy allocations as needed. Although some allocations may require pages from a partiular zone, other allocations my pull from multiple zones. Each zone is represented by a struct zone, which is defined in &lt;linux/mmzone.h&gt; [1].\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\nstruct zone {\n    unsigned long watermark[NR_WMARK];\n    unsigned long lowmem_reserve[MAX_NR_ZONES];\n    struct per_cpu_pageset pageset[NR_CPUS];\n    spinlock_t lock;\n    struct free_area free_area[MAX_ORDER]\n    spinlock_t lru_lock;\n    struct zone_lru {\n        struct list_head list;\n        unsigned long nr_saved_scan;\n    } lru[NR_LRU_LISTS];\n    struct zone_reclaim_stat reclaim_stat;\n    unsigned long pages_scanned;\n    unsigned long flags;\n    atomic_long_t vm_stat[NR_VM_ZONE_STAT_ITEMS];\n    int prev_priority;\n    unsigned int inactive_ratio;\n    wait_queue_head_t *wait_table;\n    unsigned long wait_table_hash_nr_entries;\n    unsigned long wait_table_bits;\n    struct pglist_data *zone_pgdat;\n    unsigned long zone_start_pfn;\n    unsigned long spanned_pages;\n    unsigned long present_pages;\n    const char *name;\n};\n\n\nKmalloc() is similar to malloc() in user-space, but it is just a simple interface for obtaining kernel memory in byte-sized chunks and it can be used to allocate pages. For freeing pages, we can use kfree(), which is definded in &lt;linux/slab.h&gt;, kfree() frees a block of memory previously allocated with kmalloc() [1].\n\n1\n2\n3\n4\n5\n    buf = kmalloc(BUF_SIZE, GFP_ATOMIC);\n    if (!buf)\n    /* error allocating memory ! */\n    ...\n    kfree(buf);\n\n\nFree lists data structures are the default data structures in kernel. Due to the fact that allocating and freeing data structures is one of the most common operations inside any kernel has issues, slab layer is used to solve these issues. Slab layer acts as generic data structure-chaining layer and slab layer attempts to cache frequently used data structures as they tend to be allocated and freed often, prevent memory fragmentation, which is resulted from frequent allocation and deallocation, by cached free lists are arranged contiguously, and it has many other promises that slab layer attempts to provide [1].\n\nWindows\n\nThe memory manager in Windows implements virtual memory, provides a core set of services such as memory mapped files, copy-on-write memory, large memory support, and underlying support for the cache manager.The memory manager creates the two memory pools, non-paged pool and paged pool, that the system uses to allocate memory. Non-paged pool and paged pool are located in the region of the address space that is reserved for the system and mapped into the virtual address space of each process. For the non-paged pool, it consists of virtual memory addresses that are guaranteed to reside in physical memory as long as the corresponding kernel objects are allocated. For the paged pool, it consists of virtual memory that can be paged in and out of the system. To improve performance, systems with a single processor have three paged pools, and multiprocessor systems have five paged pools [5].\n\nIt seems that Windows uses VirtualAlloc() to use a page granularity, so using VirtualAlloc can result in higher memory usage and it allows you to specify additional options for memory allocation. In order to free pages, you need to use VirtualFree() [5].\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\nLPVOID WINAPI VirtualAlloc(\n      _In_opt_ LPVOID lpAddress,\n      _In_     SIZE_T dwSize,\n      _In_     DWORD  flAllocationType,\n      _In_     DWORD  flProtect\n);\nBOOL WINAPI VirtualFree(\n      _In_ LPVOID lpAddress,\n      _In_ SIZE_T dwSize,\n      _In_ DWORD  dwFreeType\n);\n\n\nGeneral Discussion\n\nWindows and Linux has different memory management structures. In Windows, memory management uses tree data structures, uses cluster demand paging, brings 8 pages in memory simultaneously, and page replacements uses First In First Out (FIFO) algorithm. In the other hand, in Linux, memory management uses linked lists data stricture, uses demand paging with no pre-paging and it doesn't swap the entire process instead it uses a lazy swapper, swaps the necessary pages into memory only to avoid reading pages that won't be used, which decreases swap time and amount of physical memory required, and page replacement uses Least Recently Used (LRU) algorithm [13].\n\nFrom my research, it seems that Windows is built for commercial use due it's complex systems to handle large amount of data compared to linux and FreeBSD, and FreeBSD seems to follow most of Linux memory management style, but it is more stable than Linux by using different methods [1][5][7][13].\n\nConclusion\n\nTo conclude, I have discussed about the differences and similarity between Linux, FreeBSD, and Windows in these areas: concurrency, I/O, and memory management. Therefore, based on my research and understanding, I conclude that FreeBSD and Linux are an excellent operating systems because of their system simplicity compared to Windows. However, Windows complexity was made for a certain purpose, which is commercial use. In addition, FreeBSD seems to be more stable and secure than Linux. Other than that, all of the systems have similar general architecture and data flow, but they vary in the way they implement and process these parts.\n\nReferences\n\nR. Love,Linux Kernel Development, 3rd ed. Addison-Wesley Professional, 2010.\n\n\"Operating system-processes,\"Available at https://www.tutorialspoint.com/operatingsystem/osprocesses.htm(2018/10/19).\n\nA. Vara, \"How to create process in linux (part 10/15),\" Available at https://www.engineersgarage.com/tutorials/introduction-linux-part-1015.\n\nM. K. McKusick, G. Neville-Neil, and R. N. Watson,The Design and Implementation of the FreeBSD Operating System, 2nd ed. Addison-Wesley Professional, 2014.\n\n\"Memory management,\" Available at https://docs.microsoft.com/en-us/windows/desktop/memory/memory-management(2018/05/30).\n\nM. E. Russinovich, D. A. Solomon, and A. Ionescu,Windows Internals, Part 1: Covering Windows Server 2008 R2 and Windows 7,6th ed. Redmond, WA, USA: Microsoft Press, 2012.\n\nM. K. McKusick, K. Bostic, M. J. Karels, and J. S. Quarterman,The Design and Implementation of the 4.4BSD Operating System.Redwood City, CA, USA: Addison Wesley Longman Publishing Co., Inc., 1996.\n\nM. W. Lucas,Absolute Freebsd, 2Nd Edition, 2nd ed. San Francisco, CA, USA: No Starch Press, 2007.\n\nM. E. Russinovich, D. A. Solomon, and A. Ionescu,Windows Internals, Part 2: Covering Windows Server 2008 R2 and Windows 7(Windows Internals). Redmond, WA, USA: Microsoft Press, 2012.\n\nH. Haftmann, \"Completing i/o requests,\" Available at https://www-user.tu-chemnitz.de/∼heha/oneywdm/ch05d.htm.\n\nB. Bruce and M. Stokely, \"Freebsd vs. linux vs. windows 2000,\" Available at https://people.freebsd.org/∼murray/bsdflier.html.\n\nS. Hand, \"Operating systems,\" Available at https://www.cl.cam.ac.uk/teaching/1011/OpSystems/os1a-slides.pdf\n\nU. Essays, \"Compare the memory management of windows with linux,\" Available at https://www.ukessays.com/essays/engineering/compare-the-memory-management.php (2016/12/05)."

    },
  

  
    {

      "title"    : "How to get a great job",
      "url"      : "/notes/How-to-get-a-great-job",
      "content"  : "Link: https://medium.com/@marksaroufim/how-to-get-a-great-job-68cb69ddfeb1Notes  The best way to do get your dream job is to start doing it  Your goal should be to apply to jobs with a portfolio not a CV          However, a portfolio is much harder to beef up than a CV because you need to actually produce lots of visible work.        Optimizing for an amazing CV has a tremendous amount of luck involved, optimizing for a portfolio is entirely within your control — you just need to spend a few minutes everyday."

    },
  
    {

      "title"    : "Imf v3 (soon to be known as the lyt system)",
      "url"      : "/notes/IMF-v3-(Soon-to-be-known-as-the-LYT-System)",
      "content"  : "Link: https://forum.obsidian.md/t/imf-v3-soon-to-be-known-as-the-lyt-system/390Notes  Index and MOCs (Mapping of Content) is the IMF method  This method is similar to [[associative ontologies]], but MOCs is different          MOCs allow to have multiple notes to be linked together based on an intuition order rather than racing for position to describe the note      MOCs are like TOC (Table of Content)        Example of MOCs (by me)          Career                  Research                          How to be a researcher              …                                Data Science          Teaching          Kaggle                    Education                  Mathematics and Statistics                          Discrete Mathematics              Differential Calculus              Integral Calculus              Infinite Series and Sequences              Vector Calculus              Linear Algebra              Probability                                              Computer Science                          Data Structures              Algorithms              Web Development              Artificial Intelligence              Theory of Computation              Graph Theory              Software Engineering                                Machine Learning          Deep Learning          Writing                    Productivity                  Studying          Working          …                    Health                  Food          Exercise          Sleep          Physiology                    Philosophy                  God                    Learning                  Source                          Notes              …                                            MOCs cycles:          Connecting related stuff      Battling it out by forming new ideas, splitting others, and filling gaps      Forming a mature spatial map of ideas        MOCs vs. Ontologies:          Ontologies represent what is real, maps are an interpretation of what is real.      On a given topic, there should be one ontology, but there can be limitless maps.      Maps of content float above the note collection, offering an augmented and customized, but non-destructive perspective      While we will also read our maps, at the heart of the process, we are the cartographers.        MOCs uses TOCs for a specific, linear, and final sequence          Examples:                  when writing a final project like an essay or research paper          possibly to arrange notes from a lecture                    MOCs are [[Evergreen Notes]], just at the next level of emergence        Fluid Frameworks          MOCs and any variation of note consisting mostly links      tags      Transclusion-heavy notes                                      Direct Links        Naming convention          MOCs = \"related-note\" MOC      TOCs = \"topic\" TOC        Linking Your Thinking (LYT) is the new naming for IMF"

    }
  
]